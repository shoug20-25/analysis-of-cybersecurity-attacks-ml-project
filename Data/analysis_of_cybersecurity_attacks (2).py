# -*- coding: utf-8 -*-
"""analysis-of-cybersecurity-attacks.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tJGny4rOzg5fjsT96KW4Wax0rrVTGRUe
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

from google.colab import files
uploaded = files.upload()

import zipfile
import os

# فك الضغط
with zipfile.ZipFile("archive.zip", 'r') as zip_ref:
    zip_ref.extractall("dataset")  # مجلد جديد فيه الملفات

# عرض الملفات اللي انفكت
os.listdir("dataset")

import pandas as pd
df = pd.read_csv("dataset/cybersecurity_attacks.csv")

df = pd.read_csv("dataset/cybersecurity_attacks.csv")
df

# 0) imports
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing  import LabelEncoder, StandardScaler
from imblearn.over_sampling  import SMOTE

# 1) load
df = pd.read_csv("dataset/cybersecurity_attacks.csv")
print("All columns:", df.columns.tolist())

# 2) fillna
fill_values = {
    'Alerts/Warnings':    'None',
    'IDS/IPS Alerts':     'No Data',
    'Malware Indicators': 'No Detection',
    'Firewall Logs':      'No Data',
    'Proxy Information':  'No Proxy Data'
}
df.fillna({c:v for c,v in fill_values.items() if c in df.columns},
          inplace=True)

# 3) drop
to_drop = [
    'Timestamp','Source IP Address','Destination IP Address',
    'Payload Data','Geo-location Data','Proxy Information',
    'Firewall Logs','IDS/IPS Alerts','Log Source'
]
df.drop(columns=[c for c in to_drop if c in df.columns],
        inplace=True, errors='ignore')

# 4) encode categoricals
for col in df.select_dtypes(include='object').columns:
    df[col] = LabelEncoder().fit_transform(df[col])

# 5) X/y
X = df.drop(columns=['Action Taken'])
y = df['Action Taken'].apply(lambda x: 0 if x==0 else 1)

# 6) split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 7) SMOTE
sm = SMOTE(random_state=42)
X_train_res, y_train_res = sm.fit_resample(X_train, y_train)

# 8) scale
scaler       = StandardScaler().fit(X_train_res)
X_train_scaled = scaler.transform(X_train_res)
X_test_scaled  = scaler.transform(X_test)  # only X_test, لا داعي لتحويله لـ DataFrame

print("✅ preprocessing done:")
print("X_train_scaled:", X_train_scaled.shape,
      "y_train_res:", y_train_res.shape)
print("X_test_scaled:",  X_test_scaled.shape,
      "y_test:",       y_test.shape)

# ——— حفظ المصفوفات بعد المعالجة المسبقة ———
import pandas as pd

# حوّلي numpy arrays إلى DataFrame بنفس أسماء الأعمدة الأصلية
X_train_df = pd.DataFrame(X_train_scaled, columns=X.columns)
X_test_df  = pd.DataFrame(X_test_scaled,  columns=X.columns)

# خزّنيهم على شكل CSV
X_train_df.to_csv("X_train.csv", index=False)
X_test_df .to_csv("X_test.csv",  index=False)
y_train_res.to_csv("Y_train.csv", index=False)
y_test   .to_csv("Y_test.csv",  index=False)

print("✅ إعادة توليد ملفات X_train.csv, X_test.csv, Y_train.csv, Y_test.csv")

!ls

print(df.shape)

import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# 1) قراءة البيانات بعد preprocessing وبـScaled
X_train = pd.read_csv("X_train.csv").values    # شكل المصفوفة: (42354, 15)
X_test  = pd.read_csv("X_test.csv").values     # شكل المصفوفة: ( 8000, 15)
y_train = pd.read_csv("Y_train.csv").iloc[:,0] # Series بطول 42354
y_test  = pd.read_csv("Y_test.csv").iloc[:,0]  # Series بطول  8000

# 2) بناء نموذج الـANN (input_shape يعتمد على عدد الخصائص)
model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    Dense(32, activation='relu'),
    Dense(1,  activation='sigmoid')
])
model.compile(
    loss='binary_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

# 3) تدريب النموذج
model.fit(
    X_train, y_train,
    epochs=20,
    batch_size=32,
    verbose=1
)

# 4) التنبؤ على مجموعة الاختبار وتحويل الاحتمالات إلى 0/1
y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()

# بعد ما تعمل predict وتكون y_pred جاهزة:
pd.DataFrame({"prediction": y_pred}) \
  .to_csv("predictions_ANN_model.csv", index=False)

# 5) تقييم الأداء وحساب الدقة والتقرير
acc = accuracy_score(y_test, y_pred)
print(f"\n🎯 دقة ANN: {acc*100:.2f}%\n")

print("🔍 تقرير التصنيف (Classification Report):")
print(classification_report(
    y_test, y_pred,
    target_names=["No Action","Action Taken"]
))

# 6) رسم توزيع التوقعات (Bar Chart)
cm = confusion_matrix(y_test, y_pred)  # نحتاجه لاحقاً أيضاً
plt.figure(figsize=(5, 4))
counts = pd.Series(y_pred).value_counts().sort_index()
plt.bar(
    counts.index.astype(str),
    counts.values,
    color=['#29B6F6', '#FFC107']
)
plt.title("Distribution of ANN Predictions")
plt.xlabel("Predicted Class")
plt.ylabel("Count")
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

# 7) رسم مصفوفة الالتباس (Confusion Matrix) يدويّاً
plt.figure(figsize=(4, 4))
plt.imshow(cm, cmap='Blues', interpolation='nearest')
plt.title("ANN Confusion Matrix")
plt.colorbar()
plt.xticks([0,1], ["No","Yes"])
plt.yticks([0,1], ["No","Yes"])
for i in range(2):
    for j in range(2):
        plt.text(
            j, i, cm[i,j],
            ha='center', va='center',
            color='white' if cm[i,j] > cm.max()/2 else 'black'
        )
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# ——————————————————————————————————————————————————————————————
# 0) افترض أنّ المتغيّرات الجاهزة موجودة في الذاكرة:
#    X_train_res, X_test_scaled, y_train_res, y_test
# ——————————————————————————————————————————————————————————————

# 1) بناء نموذج SVM خطي سريع
model_svm = LinearSVC(
    class_weight='balanced',
    max_iter=2000,   # حدّ أقصى للتكرارات
    tol=1e-4,        # معيار الإيقاف المبكّر
    random_state=42
)

# 2) تدريب النموذج
model_svm.fit(X_train_res, y_train_res)

# 3) التنبؤ
y_pred_svm = model_svm.predict(X_test_scaled)

pd.DataFrame({"prediction": y_pred_svm})  .to_csv("predictions_SVM_model.csv", index=False)

# 4) تقييم الأداء
acc_svm = accuracy_score(y_test, y_pred_svm)
print(f"\n🎯 دقة LinearSVC: {acc_svm*100:.2f}%\n")
print("🔍 Classification Report:")
print(classification_report(
    y_test, y_pred_svm,
    target_names=["No Action", "Action Taken"]
))
print("🔢 Confusion Matrix:")
cm_svm = confusion_matrix(y_test, y_pred_svm)
print(cm_svm)

# 5) رسم توزيع التوقعات (Annotated Bar Chart)
plt.figure(figsize=(6,4))
df_vis = pd.DataFrame({"prediction": y_pred_svm})
ax = sns.countplot(
    x="prediction",
    hue="prediction",
    data=df_vis,
    palette="pastel",
    legend=False
)
ax.set_xticklabels(["No Action", "Action Taken"])
for p in ax.patches:
    ax.annotate(
        f"{int(p.get_height())}",
        (p.get_x() + p.get_width()/2, p.get_height()),
        ha='center', va='bottom'
    )
plt.title("Distribution of SVM (LinearSVC) Predictions")
plt.xlabel("Predicted Class")
plt.ylabel("Count")
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

# 6) رسم مصفوفة الالتباس Heatmap
plt.figure(figsize=(5,4))
sns.heatmap(
    cm_svm, annot=True, fmt="d", cmap="Blues",
    xticklabels=["No Action", "Action Taken"],
    yticklabels=["No Action", "Action Taken"]
)
plt.title("LinearSVC Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

import pandas as pd
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# 1)  جاهزية المتغيرات التالية (بعد المعالجة المسبقة):
#    X_train_res, X_test_scaled, y_train_res, y_test

# 2) بناء نموذج Naive Bayes وتدريبه
model_nb = GaussianNB()
model_nb.fit(X_train_res, y_train_res)

# 3) التنبؤ على مجموعة الاختبار
y_pred = model_nb.predict(X_test_scaled)

# 4) حفظ التوقعات لملف CSV
pd.DataFrame(y_pred, columns=["prediction"]) \
  .to_csv("predictions_NB_model.csv", index=False)

# 5) حساب الدقة وطباعة تقرير التصنيف ومصفوفة الالتباس
acc = accuracy_score(y_test, y_pred)
print("✅ تم تدريب Naive Bayes وحفظ التوقعات.")
print(f"🎯 Accuracy NB: {acc*100:.2f}%\n")
print("📊 Classification Report:")
print(classification_report(
    y_test, y_pred,
    target_names=["No Action", "Action Taken"]
))
cm = confusion_matrix(y_test, y_pred)
print("🔢 Confusion Matrix:")
print(cm)

# 6) رسم توزيع التوقعات (Annotated Bar Chart)
plt.figure(figsize=(6,4))
df_vis = pd.DataFrame({"prediction": y_pred})
ax = sns.countplot(
    x="prediction",
    hue="prediction",
    data=df_vis,
    palette="pastel",
    legend=False
)
ax.set_xticks([0, 1])
ax.set_xticklabels(["No Action", "Action Taken"])
for p in ax.patches:
    ax.annotate(
        f"{int(p.get_height())}",
        (p.get_x() + p.get_width()/2, p.get_height()),
        ha='center', va='bottom'
    )
plt.title("Distribution of NB Predictions", fontsize=14)
plt.xlabel("Predicted Class", fontsize=12)
plt.ylabel("Count", fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()
print("\n\n")

# 7) رسم مصفوفة الالتباس Heatmap
plt.figure(figsize=(5,4))
sns.heatmap(
    cm, annot=True, fmt="d", cmap="Blues",
    xticklabels=["No Action", "Action Taken"],
    yticklabels=["No Action", "Action Taken"]
)
plt.title("Naive Bayes Confusion Matrix", fontsize=14)
plt.xlabel("Predicted", fontsize=12)
plt.ylabel("Actual", fontsize=12)
plt.tight_layout()
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# 1) تدريب نموذج KNN
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train_res, y_train_res)

# 2) تنبؤ وحفظ التوقعات
y_pred = knn.predict(X_test_scaled)
pd.DataFrame(y_pred, columns=["prediction"]).to_csv("predictions_KNN_model.csv", index=False)

# 3) تقرير الأداء
acc = accuracy_score(y_test, y_pred)
print(f"🎯 Accuracy KNN: {acc*100:.2f}%\n")
print(classification_report(y_test, y_pred, target_names=["No Action","Action Taken"]))
print("\n\n")
# 4) مصفوفة الالتباس
cm = confusion_matrix(y_test, y_pred)
print("\n\n")
# 5) توزيع التوقعات
plt.figure(figsize=(6,4))
ax = sns.countplot(x=y_pred, hue=y_pred, palette="pastel", data=pd.DataFrame({"prediction":y_pred}), legend=False)
ax.set_xticks([0, 1])
ax.set_xticklabels(["No Action","Action Taken"])
for p in ax.patches:
    ax.annotate(int(p.get_height()), (p.get_x()+p.get_width()/2, p.get_height()), ha='center', va='bottom')
plt.title("Distribution of KNN Predictions", fontsize=14)
plt.xlabel("Predicted Class"); plt.ylabel("Count")
plt.show()
print("\n\n")
# 6) heatmap للـ Confusion Matrix
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["No Action","Action Taken"],
            yticklabels=["No Action","Action Taken"])
plt.title("KNN Confusion Matrix", fontsize=14)
plt.xlabel("Predicted"); plt.ylabel("Actual")
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# 1) تدريب نموذج Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
rf.fit(X_train_res, y_train_res)

# 2) تنبؤ وحفظ التوقعات
y_pred = rf.predict(X_test_scaled)
pd.DataFrame(y_pred, columns=["prediction"]).to_csv("predictions_RF_model.csv", index=False)

# 3) تقرير الأداء
acc = accuracy_score(y_test, y_pred)
print(f"🎯 Accuracy Random Forest: {acc*100:.2f}%\n")
print(classification_report(y_test, y_pred, target_names=["No Action","Action Taken"]))
print("\n\n")
# 4) مصفوفة الالتباس
cm = confusion_matrix(y_test, y_pred)
print("\n\n")
# 5) توزيع التوقعات
plt.figure(figsize=(6,4))
ax = sns.countplot(x=y_pred, hue=y_pred, palette="pastel", data=pd.DataFrame({"prediction":y_pred}), legend=False)
ax.set_xticks([0, 1])
ax.set_xticklabels(["No Action","Action Taken"])
for p in ax.patches:
    ax.annotate(int(p.get_height()), (p.get_x()+p.get_width()/2, p.get_height()), ha='center', va='bottom')
plt.title("Distribution of RF Predictions", fontsize=14)
plt.xlabel("Predicted Class"); plt.ylabel("Count")
plt.show()
print("\n\n")
# 6) heatmap للـ Confusion Matrix
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["No Action","Action Taken"],
            yticklabels=["No Action","Action Taken"])
plt.title("RF Confusion Matrix", fontsize=14)
plt.xlabel("Predicted"); plt.ylabel("Actual")
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# 1) تدريب نموذج Decision Tree
dt = DecisionTreeClassifier(random_state=42, class_weight='balanced')
dt.fit(X_train_res, y_train_res)

# 2) تنبؤ وحفظ التوقعات
y_pred = dt.predict(X_test_scaled)
pd.DataFrame(y_pred, columns=["prediction"]).to_csv("predictions_DT_model.csv", index=False)

# 3) تقرير الأداء
acc = accuracy_score(y_test, y_pred)
print(f"🎯 Accuracy Decision Tree: {acc*100:.2f}%\n")
print(classification_report(y_test, y_pred, target_names=["No Action","Action Taken"]))
print("\n\n")
# 4) مصفوفة الالتباس
cm = confusion_matrix(y_test, y_pred)
print("\n\n")
# 5) توزيع التوقعات
plt.figure(figsize=(6,4))
ax = sns.countplot(x=y_pred, hue=y_pred, palette="pastel", data=pd.DataFrame({"prediction":y_pred}), legend=False)
ax.set_xticks([0, 1])
ax.set_xticklabels(["No Action","Action Taken"])
for p in ax.patches:
    ax.annotate(int(p.get_height()), (p.get_x()+p.get_width()/2, p.get_height()), ha='center', va='bottom')
plt.title("Distribution of DT Predictions", fontsize=14)
plt.xlabel("Predicted Class"); plt.ylabel("Count")
plt.show()
print("\n\n")
# 6) heatmap للـ Confusion Matrix
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["No Action","Action Taken"],
            yticklabels=["No Action","Action Taken"])
plt.title("DT Confusion Matrix", fontsize=14)
plt.xlabel("Predicted"); plt.ylabel("Actual")
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# 1) تدريب نموذج Logistic Regression
lr = LogisticRegression(max_iter=5000, class_weight='balanced', solver='saga', random_state=42)
lr.fit(X_train_res, y_train_res)

# 2) تنبؤ وحفظ التوقعات
y_pred = lr.predict(X_test_scaled)
pd.DataFrame(y_pred, columns=["prediction"]).to_csv("predictions_LR_model.csv", index=False)

# 3) تقرير الأداء
acc = accuracy_score(y_test, y_pred)
print(f"🎯 Accuracy Logistic Regression: {acc*100:.2f}%\n")
print(classification_report(y_test, y_pred, target_names=["No Action","Action Taken"]))

# 4) مصفوفة الالتباس
cm = confusion_matrix(y_test, y_pred)
print("\n\n")

# 5) توزيع التوقعات
plt.figure(figsize=(6,4))
ax = sns.countplot(x=y_pred, hue=y_pred, palette="pastel", data=pd.DataFrame({"prediction":y_pred}), legend=False)
ax.set_xticks([0, 1])
ax.set_xticklabels(["No Action","Action Taken"])
for p in ax.patches:
    ax.annotate(int(p.get_height()), (p.get_x()+p.get_width()/2, p.get_height()), ha='center', va='bottom')
plt.title("Distribution of LR Predictions", fontsize=14)
plt.xlabel("Predicted Class"); plt.ylabel("Count")
plt.show()
print("\n\n")

# 6) heatmap للـ Confusion Matrix
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["No Action","Action Taken"],
            yticklabels=["No Action","Action Taken"])
plt.title("LR Confusion Matrix", fontsize=14)
plt.xlabel("Predicted"); plt.ylabel("Actual")
plt.show()

import pandas as pd
from sklearn.metrics import accuracy_score

# 1) خزننا مسميات النماذج وملفات التوقعات
models = {
    "ANN":           "predictions_ANN_model.csv",
    "SVM":           "predictions_SVM_model.csv",
    "Naive Bayes":   "predictions_NB_model.csv",
    "KNN":           "predictions_KNN_model.csv",
    "Random Forest": "predictions_RF_model.csv",
    "Decision Tree": "predictions_DT_model.csv",
    "Logistic Reg.": "predictions_LR_model.csv"
}

# 2) اقراؤنا للقيم الحقيقية
y_true_full = pd.read_csv("Y_test.csv").iloc[:, 0]

accuracies = {}
for name, filename in models.items():
    # بدل dataset/cybersecurity_attacks.csv
    # نقرو ملف التوقعات اللي للـ model
    df_pred = pd.read_csv(filename)
    # تأكد إنه فعلاً عمود prediction موجود
    if "prediction" not in df_pred.columns:
        raise KeyError(f"File {filename} has no column 'prediction', found {df_pred.columns.tolist()}")
    y_pred = df_pred["prediction"]

    # لو عدد التوقعات أقل من y_true_full نقص y_true_full عشان تطابق الأطوال
    y_true = (y_true_full if len(y_true_full) == len(y_pred)
              else y_true_full.iloc[:len(y_pred)])

    acc = accuracy_score(y_true, y_pred)
    accuracies[name] = acc

# 3) اطبع النتائج
print("🎯 Accuracy for all models:\n")
for name, acc in accuracies.items():
    print(f" - {name:14s}: {acc*100:5.2f}%")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score

# 1) مسميات النماذج وملفات التوقعات
models = {
    "ANN":           "predictions_ANN_model.csv",
    "SVM":           "predictions_SVM_model.csv",
    "Naive Bayes":   "predictions_NB_model.csv",
    "KNN":           "predictions_KNN_model.csv",
    "Random Forest": "predictions_RF_model.csv",
    "Decision Tree": "predictions_DT_model.csv",
    "Logistic Reg.": "predictions_LR_model.csv"
}

# 2) قراءة القيم الحقيقية مرة وحدة
y_true_full = pd.read_csv("Y_test.csv").iloc[:, 0]

dist_data = []
acc_data  = []

for name, path in models.items():
    # 3) نقرأ ملف التوقعات الخاص بالنموذج
    df_pred = pd.read_csv(path)
    if "prediction" not in df_pred.columns:
        raise KeyError(f"{path} لا يحتوي على عمود 'prediction'")
    y_pred = df_pred["prediction"]

    # 4) نقص الحقيقة إذا عدد التوقعات أقل
    if len(y_pred) != len(y_true_full):
        y_true = y_true_full.iloc[:len(y_pred)]
    else:
        y_true = y_true_full

    # 5) نحسب توزيع الفئات (عدد No Action مقابل Action Taken)
    counts = y_pred.value_counts().to_dict()
    dist_data.append({
        "Model": name,
        "No Action": counts.get(0, 0),
        "Action Taken": counts.get(1, 0)
    })

    # 6) نحسب الدقّة
    acc = accuracy_score(y_true, y_pred)
    acc_data.append({"Model": name, "Accuracy": acc})

# 7) نحوله لــDataFrame
df_dist = pd.DataFrame(dist_data)
df_acc  = pd.DataFrame(acc_data)

# ——— رسم توزيع التوقعات لكل موديل ———
df_long = df_dist.melt(
    id_vars="Model",
    value_vars=["No Action","Action Taken"],
    var_name="Predicted Class",
    value_name="Count"
)
plt.figure(figsize=(12, 6))
sns.barplot(
    data=df_long,
    x="Model", y="Count",
    hue="Predicted Class",
    palette="pastel"
)
plt.title("📊 Distribution of Predictions for All Models", fontsize=16)
plt.xticks(rotation=15)
plt.legend(title="Predicted Class")
plt.tight_layout()
plt.show()

# ——— رسم مقارنة الدقّة ———
plt.figure(figsize=(10, 5))
sns.barplot(
    data=df_acc,
    x="Model", y="Accuracy",
    palette="pastel"
)
plt.title("🎯 Accuracy Comparison of All Models", fontsize=16)
plt.ylim(0, 1)
plt.xticks(rotation=15)
plt.tight_layout()
plt.show()

"""Welcome to Incribo's synthetic cyber dataset! Crafted with precision, this dataset offers a realistic representation of travel history, making it an ideal playground for various analytical tasks.

Use the cybersecurity attacks dataset to help you assess the heatmaps, attack signatures, types, and more!

Remember, this is just a sample! If you're intrigued and want access to the complete dataset or have specific requirements, don't hesitate to contact us(info@incribo.com). Happy building!

Columns:
        
* **Timestamp:** The time at which the network activity occurred.
* **Source IP Address:** The IP address of the sender or initiator of the network traffic.
* **Destination IP Address:** The IP address of the receiver or target of the network traffic.
* **Source Port:** The port number used by the source IP address.
* **Destination Port:** The port number used by the destination IP address.
* **Protocol:** The communication protocol used (e.g., TCP, UDP, ICMP).
* **Packet Length:** The size of the packet in bytes.
* **Packet Type:** Type of packet (e.g., data packet, control packet).
* **Traffic Type:** The type of traffic (e.g., web traffic, email traffic).
* **Payload Data:** The actual data transmitted in the packet.
* **Malware Indicators:** Indicators of potentially malicious activity or presence of malware.
* **Anomaly Scores:** Scores indicating deviations from expected behavior, used for anomaly detection.
* **Alerts/Warnings:** Notifications or warnings generated by security systems or monitoring tools.
* **Attack Type:** Type of attack detected or suspected (e.g., DDoS, SQL injection).
* **Attack Signature:** Specific patterns or signatures associated with known attacks.
* **Action Taken:** Actions performed in response to detected threats or anomalies.
* **Severity Level:** The level of severity associated with an alert or event (e.g., low, medium, high).
* **User Information:** Information about the user involved in the network activity.
* **Device Information:** Information about the device involved in the network activity (e.g., device type, operating system).
* **Network Segment:** The segment or subnet of the network where the activity occurred.
* **Geo-location Data:** Geographical location information associated with IP addresses.
* **Proxy Information:** Information about proxy servers involved in the network communication.
* **Firewall Logs:** Logs generated by firewall devices indicating allowed or blocked traffic.
* **IDS/IPS Alerts:** Alerts generated by Intrusion Detection Systems (IDS) or Intrusion Prevention Systems (IPS) indicating suspicious or malicious activity.
* **Log Source:** The source or origin of the log entry (e.g., name of the logging system or device).
"""