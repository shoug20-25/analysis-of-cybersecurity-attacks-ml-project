# -*- coding: utf-8 -*-
"""analysis-of-cybersecurity-attacks.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tJGny4rOzg5fjsT96KW4Wax0rrVTGRUe
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

from google.colab import files
uploaded = files.upload()

import zipfile
import os

# ÙÙƒ Ø§Ù„Ø¶ØºØ·
with zipfile.ZipFile("archive.zip", 'r') as zip_ref:
    zip_ref.extractall("dataset")  # Ù…Ø¬Ù„Ø¯ Ø¬Ø¯ÙŠØ¯ ÙÙŠÙ‡ Ø§Ù„Ù…Ù„ÙØ§Øª

# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù„ÙŠ Ø§Ù†ÙÙƒØª
os.listdir("dataset")

import pandas as pd
df = pd.read_csv("dataset/cybersecurity_attacks.csv")

df = pd.read_csv("dataset/cybersecurity_attacks.csv")
df

# 0) imports
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing  import LabelEncoder, StandardScaler
from imblearn.over_sampling  import SMOTE

# 1) load
df = pd.read_csv("dataset/cybersecurity_attacks.csv")
print("All columns:", df.columns.tolist())

# 2) fillna
fill_values = {
    'Alerts/Warnings':    'None',
    'IDS/IPS Alerts':     'No Data',
    'Malware Indicators': 'No Detection',
    'Firewall Logs':      'No Data',
    'Proxy Information':  'No Proxy Data'
}
df.fillna({c:v for c,v in fill_values.items() if c in df.columns},
          inplace=True)

# 3) drop
to_drop = [
    'Timestamp','Source IP Address','Destination IP Address',
    'Payload Data','Geo-location Data','Proxy Information',
    'Firewall Logs','IDS/IPS Alerts','Log Source'
]
df.drop(columns=[c for c in to_drop if c in df.columns],
        inplace=True, errors='ignore')

# 4) encode categoricals
for col in df.select_dtypes(include='object').columns:
    df[col] = LabelEncoder().fit_transform(df[col])

# 5) X/y
X = df.drop(columns=['Action Taken'])
y = df['Action Taken'].apply(lambda x: 0 if x==0 else 1)

# 6) split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 7) SMOTE
sm = SMOTE(random_state=42)
X_train_res, y_train_res = sm.fit_resample(X_train, y_train)

# 8) scale
scaler       = StandardScaler().fit(X_train_res)
X_train_scaled = scaler.transform(X_train_res)
X_test_scaled  = scaler.transform(X_test)  # only X_test, Ù„Ø§ Ø¯Ø§Ø¹ÙŠ Ù„ØªØ­ÙˆÙŠÙ„Ù‡ Ù„Ù€ DataFrame

print("âœ… preprocessing done:")
print("X_train_scaled:", X_train_scaled.shape,
      "y_train_res:", y_train_res.shape)
print("X_test_scaled:",  X_test_scaled.shape,
      "y_test:",       y_test.shape)

# â€”â€”â€” Ø­ÙØ¸ Ø§Ù„Ù…ØµÙÙˆÙØ§Øª Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© â€”â€”â€”
import pandas as pd

# Ø­ÙˆÙ‘Ù„ÙŠ numpy arrays Ø¥Ù„Ù‰ DataFrame Ø¨Ù†ÙØ³ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
X_train_df = pd.DataFrame(X_train_scaled, columns=X.columns)
X_test_df  = pd.DataFrame(X_test_scaled,  columns=X.columns)

# Ø®Ø²Ù‘Ù†ÙŠÙ‡Ù… Ø¹Ù„Ù‰ Ø´ÙƒÙ„ CSV
X_train_df.to_csv("X_train.csv", index=False)
X_test_df .to_csv("X_test.csv",  index=False)
y_train_res.to_csv("Y_train.csv", index=False)
y_test   .to_csv("Y_test.csv",  index=False)

print("âœ… Ø¥Ø¹Ø§Ø¯Ø© ØªÙˆÙ„ÙŠØ¯ Ù…Ù„ÙØ§Øª X_train.csv, X_test.csv, Y_train.csv, Y_test.csv")

!ls

print(df.shape)

import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# 1) Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ preprocessing ÙˆØ¨Ù€Scaled
X_train = pd.read_csv("X_train.csv").values    # Ø´ÙƒÙ„ Ø§Ù„Ù…ØµÙÙˆÙØ©: (42354, 15)
X_test  = pd.read_csv("X_test.csv").values     # Ø´ÙƒÙ„ Ø§Ù„Ù…ØµÙÙˆÙØ©: ( 8000, 15)
y_train = pd.read_csv("Y_train.csv").iloc[:,0] # Series Ø¨Ø·ÙˆÙ„ 42354
y_test  = pd.read_csv("Y_test.csv").iloc[:,0]  # Series Ø¨Ø·ÙˆÙ„  8000

# 2) Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù€ANN (input_shape ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„Ø®ØµØ§Ø¦Øµ)
model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    Dense(32, activation='relu'),
    Dense(1,  activation='sigmoid')
])
model.compile(
    loss='binary_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

# 3) ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model.fit(
    X_train, y_train,
    epochs=20,
    batch_size=32,
    verbose=1
)

# 4) Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙˆØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø¥Ù„Ù‰ 0/1
y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()

# Ø¨Ø¹Ø¯ Ù…Ø§ ØªØ¹Ù…Ù„ predict ÙˆØªÙƒÙˆÙ† y_pred Ø¬Ø§Ù‡Ø²Ø©:
pd.DataFrame({"prediction": y_pred}) \
  .to_csv("predictions_ANN_model.csv", index=False)

# 5) ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø© ÙˆØ§Ù„ØªÙ‚Ø±ÙŠØ±
acc = accuracy_score(y_test, y_pred)
print(f"\nğŸ¯ Ø¯Ù‚Ø© ANN: {acc*100:.2f}%\n")

print("ğŸ” ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ (Classification Report):")
print(classification_report(
    y_test, y_pred,
    target_names=["No Action","Action Taken"]
))

# 6) Ø±Ø³Ù… ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª (Bar Chart)
cm = confusion_matrix(y_test, y_pred)  # Ù†Ø­ØªØ§Ø¬Ù‡ Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø£ÙŠØ¶Ø§Ù‹
plt.figure(figsize=(5, 4))
counts = pd.Series(y_pred).value_counts().sort_index()
plt.bar(
    counts.index.astype(str),
    counts.values,
    color=['#29B6F6', '#FFC107']
)
plt.title("Distribution of ANN Predictions")
plt.xlabel("Predicted Class")
plt.ylabel("Count")
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

# 7) Ø±Ø³Ù… Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³ (Confusion Matrix) ÙŠØ¯ÙˆÙŠÙ‘Ø§Ù‹
plt.figure(figsize=(4, 4))
plt.imshow(cm, cmap='Blues', interpolation='nearest')
plt.title("ANN Confusion Matrix")
plt.colorbar()
plt.xticks([0,1], ["No","Yes"])
plt.yticks([0,1], ["No","Yes"])
for i in range(2):
    for j in range(2):
        plt.text(
            j, i, cm[i,j],
            ha='center', va='center',
            color='white' if cm[i,j] > cm.max()/2 else 'black'
        )
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 0) Ø§ÙØªØ±Ø¶ Ø£Ù†Ù‘ Ø§Ù„Ù…ØªØºÙŠÙ‘Ø±Ø§Øª Ø§Ù„Ø¬Ø§Ù‡Ø²Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©:
#    X_train_res, X_test_scaled, y_train_res, y_test
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# 1) Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ SVM Ø®Ø·ÙŠ Ø³Ø±ÙŠØ¹
model_svm = LinearSVC(
    class_weight='balanced',
    max_iter=2000,   # Ø­Ø¯Ù‘ Ø£Ù‚ØµÙ‰ Ù„Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
    tol=1e-4,        # Ù…Ø¹ÙŠØ§Ø± Ø§Ù„Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø¨ÙƒÙ‘Ø±
    random_state=42
)

# 2) ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model_svm.fit(X_train_res, y_train_res)

# 3) Ø§Ù„ØªÙ†Ø¨Ø¤
y_pred_svm = model_svm.predict(X_test_scaled)

pd.DataFrame({"prediction": y_pred_svm})  .to_csv("predictions_SVM_model.csv", index=False)

# 4) ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡
acc_svm = accuracy_score(y_test, y_pred_svm)
print(f"\nğŸ¯ Ø¯Ù‚Ø© LinearSVC: {acc_svm*100:.2f}%\n")
print("ğŸ” Classification Report:")
print(classification_report(
    y_test, y_pred_svm,
    target_names=["No Action", "Action Taken"]
))
print("ğŸ”¢ Confusion Matrix:")
cm_svm = confusion_matrix(y_test, y_pred_svm)
print(cm_svm)

# 5) Ø±Ø³Ù… ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª (Annotated Bar Chart)
plt.figure(figsize=(6,4))
df_vis = pd.DataFrame({"prediction": y_pred_svm})
ax = sns.countplot(
    x="prediction",
    hue="prediction",
    data=df_vis,
    palette="pastel",
    legend=False
)
ax.set_xticklabels(["No Action", "Action Taken"])
for p in ax.patches:
    ax.annotate(
        f"{int(p.get_height())}",
        (p.get_x() + p.get_width()/2, p.get_height()),
        ha='center', va='bottom'
    )
plt.title("Distribution of SVM (LinearSVC) Predictions")
plt.xlabel("Predicted Class")
plt.ylabel("Count")
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

# 6) Ø±Ø³Ù… Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³ Heatmap
plt.figure(figsize=(5,4))
sns.heatmap(
    cm_svm, annot=True, fmt="d", cmap="Blues",
    xticklabels=["No Action", "Action Taken"],
    yticklabels=["No Action", "Action Taken"]
)
plt.title("LinearSVC Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

import pandas as pd
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# 1)  Ø¬Ø§Ù‡Ø²ÙŠØ© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© (Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø©):
#    X_train_res, X_test_scaled, y_train_res, y_test

# 2) Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Naive Bayes ÙˆØªØ¯Ø±ÙŠØ¨Ù‡
model_nb = GaussianNB()
model_nb.fit(X_train_res, y_train_res)

# 3) Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
y_pred = model_nb.predict(X_test_scaled)

# 4) Ø­ÙØ¸ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ù„Ù…Ù„Ù CSV
pd.DataFrame(y_pred, columns=["prediction"]) \
  .to_csv("predictions_NB_model.csv", index=False)

# 5) Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø© ÙˆØ·Ø¨Ø§Ø¹Ø© ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ ÙˆÙ…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³
acc = accuracy_score(y_test, y_pred)
print("âœ… ØªÙ… ØªØ¯Ø±ÙŠØ¨ Naive Bayes ÙˆØ­ÙØ¸ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª.")
print(f"ğŸ¯ Accuracy NB: {acc*100:.2f}%\n")
print("ğŸ“Š Classification Report:")
print(classification_report(
    y_test, y_pred,
    target_names=["No Action", "Action Taken"]
))
cm = confusion_matrix(y_test, y_pred)
print("ğŸ”¢ Confusion Matrix:")
print(cm)

# 6) Ø±Ø³Ù… ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª (Annotated Bar Chart)
plt.figure(figsize=(6,4))
df_vis = pd.DataFrame({"prediction": y_pred})
ax = sns.countplot(
    x="prediction",
    hue="prediction",
    data=df_vis,
    palette="pastel",
    legend=False
)
ax.set_xticks([0, 1])
ax.set_xticklabels(["No Action", "Action Taken"])
for p in ax.patches:
    ax.annotate(
        f"{int(p.get_height())}",
        (p.get_x() + p.get_width()/2, p.get_height()),
        ha='center', va='bottom'
    )
plt.title("Distribution of NB Predictions", fontsize=14)
plt.xlabel("Predicted Class", fontsize=12)
plt.ylabel("Count", fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()
print("\n\n")

# 7) Ø±Ø³Ù… Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³ Heatmap
plt.figure(figsize=(5,4))
sns.heatmap(
    cm, annot=True, fmt="d", cmap="Blues",
    xticklabels=["No Action", "Action Taken"],
    yticklabels=["No Action", "Action Taken"]
)
plt.title("Naive Bayes Confusion Matrix", fontsize=14)
plt.xlabel("Predicted", fontsize=12)
plt.ylabel("Actual", fontsize=12)
plt.tight_layout()
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# 1) ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ KNN
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train_res, y_train_res)

# 2) ØªÙ†Ø¨Ø¤ ÙˆØ­ÙØ¸ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª
y_pred = knn.predict(X_test_scaled)
pd.DataFrame(y_pred, columns=["prediction"]).to_csv("predictions_KNN_model.csv", index=False)

# 3) ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡
acc = accuracy_score(y_test, y_pred)
print(f"ğŸ¯ Accuracy KNN: {acc*100:.2f}%\n")
print(classification_report(y_test, y_pred, target_names=["No Action","Action Taken"]))
print("\n\n")
# 4) Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³
cm = confusion_matrix(y_test, y_pred)
print("\n\n")
# 5) ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª
plt.figure(figsize=(6,4))
ax = sns.countplot(x=y_pred, hue=y_pred, palette="pastel", data=pd.DataFrame({"prediction":y_pred}), legend=False)
ax.set_xticks([0, 1])
ax.set_xticklabels(["No Action","Action Taken"])
for p in ax.patches:
    ax.annotate(int(p.get_height()), (p.get_x()+p.get_width()/2, p.get_height()), ha='center', va='bottom')
plt.title("Distribution of KNN Predictions", fontsize=14)
plt.xlabel("Predicted Class"); plt.ylabel("Count")
plt.show()
print("\n\n")
# 6) heatmap Ù„Ù„Ù€ Confusion Matrix
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["No Action","Action Taken"],
            yticklabels=["No Action","Action Taken"])
plt.title("KNN Confusion Matrix", fontsize=14)
plt.xlabel("Predicted"); plt.ylabel("Actual")
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# 1) ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
rf.fit(X_train_res, y_train_res)

# 2) ØªÙ†Ø¨Ø¤ ÙˆØ­ÙØ¸ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª
y_pred = rf.predict(X_test_scaled)
pd.DataFrame(y_pred, columns=["prediction"]).to_csv("predictions_RF_model.csv", index=False)

# 3) ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡
acc = accuracy_score(y_test, y_pred)
print(f"ğŸ¯ Accuracy Random Forest: {acc*100:.2f}%\n")
print(classification_report(y_test, y_pred, target_names=["No Action","Action Taken"]))
print("\n\n")
# 4) Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³
cm = confusion_matrix(y_test, y_pred)
print("\n\n")
# 5) ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª
plt.figure(figsize=(6,4))
ax = sns.countplot(x=y_pred, hue=y_pred, palette="pastel", data=pd.DataFrame({"prediction":y_pred}), legend=False)
ax.set_xticks([0, 1])
ax.set_xticklabels(["No Action","Action Taken"])
for p in ax.patches:
    ax.annotate(int(p.get_height()), (p.get_x()+p.get_width()/2, p.get_height()), ha='center', va='bottom')
plt.title("Distribution of RF Predictions", fontsize=14)
plt.xlabel("Predicted Class"); plt.ylabel("Count")
plt.show()
print("\n\n")
# 6) heatmap Ù„Ù„Ù€ Confusion Matrix
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["No Action","Action Taken"],
            yticklabels=["No Action","Action Taken"])
plt.title("RF Confusion Matrix", fontsize=14)
plt.xlabel("Predicted"); plt.ylabel("Actual")
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# 1) ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Decision Tree
dt = DecisionTreeClassifier(random_state=42, class_weight='balanced')
dt.fit(X_train_res, y_train_res)

# 2) ØªÙ†Ø¨Ø¤ ÙˆØ­ÙØ¸ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª
y_pred = dt.predict(X_test_scaled)
pd.DataFrame(y_pred, columns=["prediction"]).to_csv("predictions_DT_model.csv", index=False)

# 3) ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡
acc = accuracy_score(y_test, y_pred)
print(f"ğŸ¯ Accuracy Decision Tree: {acc*100:.2f}%\n")
print(classification_report(y_test, y_pred, target_names=["No Action","Action Taken"]))
print("\n\n")
# 4) Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³
cm = confusion_matrix(y_test, y_pred)
print("\n\n")
# 5) ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª
plt.figure(figsize=(6,4))
ax = sns.countplot(x=y_pred, hue=y_pred, palette="pastel", data=pd.DataFrame({"prediction":y_pred}), legend=False)
ax.set_xticks([0, 1])
ax.set_xticklabels(["No Action","Action Taken"])
for p in ax.patches:
    ax.annotate(int(p.get_height()), (p.get_x()+p.get_width()/2, p.get_height()), ha='center', va='bottom')
plt.title("Distribution of DT Predictions", fontsize=14)
plt.xlabel("Predicted Class"); plt.ylabel("Count")
plt.show()
print("\n\n")
# 6) heatmap Ù„Ù„Ù€ Confusion Matrix
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["No Action","Action Taken"],
            yticklabels=["No Action","Action Taken"])
plt.title("DT Confusion Matrix", fontsize=14)
plt.xlabel("Predicted"); plt.ylabel("Actual")
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# 1) ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Logistic Regression
lr = LogisticRegression(max_iter=5000, class_weight='balanced', solver='saga', random_state=42)
lr.fit(X_train_res, y_train_res)

# 2) ØªÙ†Ø¨Ø¤ ÙˆØ­ÙØ¸ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª
y_pred = lr.predict(X_test_scaled)
pd.DataFrame(y_pred, columns=["prediction"]).to_csv("predictions_LR_model.csv", index=False)

# 3) ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡
acc = accuracy_score(y_test, y_pred)
print(f"ğŸ¯ Accuracy Logistic Regression: {acc*100:.2f}%\n")
print(classification_report(y_test, y_pred, target_names=["No Action","Action Taken"]))

# 4) Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³
cm = confusion_matrix(y_test, y_pred)
print("\n\n")

# 5) ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª
plt.figure(figsize=(6,4))
ax = sns.countplot(x=y_pred, hue=y_pred, palette="pastel", data=pd.DataFrame({"prediction":y_pred}), legend=False)
ax.set_xticks([0, 1])
ax.set_xticklabels(["No Action","Action Taken"])
for p in ax.patches:
    ax.annotate(int(p.get_height()), (p.get_x()+p.get_width()/2, p.get_height()), ha='center', va='bottom')
plt.title("Distribution of LR Predictions", fontsize=14)
plt.xlabel("Predicted Class"); plt.ylabel("Count")
plt.show()
print("\n\n")

# 6) heatmap Ù„Ù„Ù€ Confusion Matrix
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["No Action","Action Taken"],
            yticklabels=["No Action","Action Taken"])
plt.title("LR Confusion Matrix", fontsize=14)
plt.xlabel("Predicted"); plt.ylabel("Actual")
plt.show()

import pandas as pd
from sklearn.metrics import accuracy_score

# 1) Ø®Ø²Ù†Ù†Ø§ Ù…Ø³Ù…ÙŠØ§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆÙ…Ù„ÙØ§Øª Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª
models = {
    "ANN":           "predictions_ANN_model.csv",
    "SVM":           "predictions_SVM_model.csv",
    "Naive Bayes":   "predictions_NB_model.csv",
    "KNN":           "predictions_KNN_model.csv",
    "Random Forest": "predictions_RF_model.csv",
    "Decision Tree": "predictions_DT_model.csv",
    "Logistic Reg.": "predictions_LR_model.csv"
}

# 2) Ø§Ù‚Ø±Ø§Ø¤Ù†Ø§ Ù„Ù„Ù‚ÙŠÙ… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©
y_true_full = pd.read_csv("Y_test.csv").iloc[:, 0]

accuracies = {}
for name, filename in models.items():
    # Ø¨Ø¯Ù„ dataset/cybersecurity_attacks.csv
    # Ù†Ù‚Ø±Ùˆ Ù…Ù„Ù Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ù„ÙŠ Ù„Ù„Ù€ model
    df_pred = pd.read_csv(filename)
    # ØªØ£ÙƒØ¯ Ø¥Ù†Ù‡ ÙØ¹Ù„Ø§Ù‹ Ø¹Ù…ÙˆØ¯ prediction Ù…ÙˆØ¬ÙˆØ¯
    if "prediction" not in df_pred.columns:
        raise KeyError(f"File {filename} has no column 'prediction', found {df_pred.columns.tolist()}")
    y_pred = df_pred["prediction"]

    # Ù„Ùˆ Ø¹Ø¯Ø¯ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø£Ù‚Ù„ Ù…Ù† y_true_full Ù†Ù‚Øµ y_true_full Ø¹Ø´Ø§Ù† ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø£Ø·ÙˆØ§Ù„
    y_true = (y_true_full if len(y_true_full) == len(y_pred)
              else y_true_full.iloc[:len(y_pred)])

    acc = accuracy_score(y_true, y_pred)
    accuracies[name] = acc

# 3) Ø§Ø·Ø¨Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
print("ğŸ¯ Accuracy for all models:\n")
for name, acc in accuracies.items():
    print(f" - {name:14s}: {acc*100:5.2f}%")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score

# 1) Ù…Ø³Ù…ÙŠØ§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆÙ…Ù„ÙØ§Øª Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª
models = {
    "ANN":           "predictions_ANN_model.csv",
    "SVM":           "predictions_SVM_model.csv",
    "Naive Bayes":   "predictions_NB_model.csv",
    "KNN":           "predictions_KNN_model.csv",
    "Random Forest": "predictions_RF_model.csv",
    "Decision Tree": "predictions_DT_model.csv",
    "Logistic Reg.": "predictions_LR_model.csv"
}

# 2) Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù…Ø±Ø© ÙˆØ­Ø¯Ø©
y_true_full = pd.read_csv("Y_test.csv").iloc[:, 0]

dist_data = []
acc_data  = []

for name, path in models.items():
    # 3) Ù†Ù‚Ø±Ø£ Ù…Ù„Ù Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ø®Ø§Øµ Ø¨Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    df_pred = pd.read_csv(path)
    if "prediction" not in df_pred.columns:
        raise KeyError(f"{path} Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ 'prediction'")
    y_pred = df_pred["prediction"]

    # 4) Ù†Ù‚Øµ Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø© Ø¥Ø°Ø§ Ø¹Ø¯Ø¯ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø£Ù‚Ù„
    if len(y_pred) != len(y_true_full):
        y_true = y_true_full.iloc[:len(y_pred)]
    else:
        y_true = y_true_full

    # 5) Ù†Ø­Ø³Ø¨ ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª (Ø¹Ø¯Ø¯ No Action Ù…Ù‚Ø§Ø¨Ù„ Action Taken)
    counts = y_pred.value_counts().to_dict()
    dist_data.append({
        "Model": name,
        "No Action": counts.get(0, 0),
        "Action Taken": counts.get(1, 0)
    })

    # 6) Ù†Ø­Ø³Ø¨ Ø§Ù„Ø¯Ù‚Ù‘Ø©
    acc = accuracy_score(y_true, y_pred)
    acc_data.append({"Model": name, "Accuracy": acc})

# 7) Ù†Ø­ÙˆÙ„Ù‡ Ù„Ù€Ù€DataFrame
df_dist = pd.DataFrame(dist_data)
df_acc  = pd.DataFrame(acc_data)

# â€”â€”â€” Ø±Ø³Ù… ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ù„ÙƒÙ„ Ù…ÙˆØ¯ÙŠÙ„ â€”â€”â€”
df_long = df_dist.melt(
    id_vars="Model",
    value_vars=["No Action","Action Taken"],
    var_name="Predicted Class",
    value_name="Count"
)
plt.figure(figsize=(12, 6))
sns.barplot(
    data=df_long,
    x="Model", y="Count",
    hue="Predicted Class",
    palette="pastel"
)
plt.title("ğŸ“Š Distribution of Predictions for All Models", fontsize=16)
plt.xticks(rotation=15)
plt.legend(title="Predicted Class")
plt.tight_layout()
plt.show()

# â€”â€”â€” Ø±Ø³Ù… Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¯Ù‚Ù‘Ø© â€”â€”â€”
plt.figure(figsize=(10, 5))
sns.barplot(
    data=df_acc,
    x="Model", y="Accuracy",
    palette="pastel"
)
plt.title("ğŸ¯ Accuracy Comparison of All Models", fontsize=16)
plt.ylim(0, 1)
plt.xticks(rotation=15)
plt.tight_layout()
plt.show()

"""Welcome to Incribo's synthetic cyber dataset! Crafted with precision, this dataset offers a realistic representation of travel history, making it an ideal playground for various analytical tasks.

Use the cybersecurity attacks dataset to help you assess the heatmaps, attack signatures, types, and more!

Remember, this is just a sample! If you're intrigued and want access to the complete dataset or have specific requirements, don't hesitate to contact us(info@incribo.com). Happy building!

Columns:
        
* **Timestamp:** The time at which the network activity occurred.
* **Source IP Address:** The IP address of the sender or initiator of the network traffic.
* **Destination IP Address:** The IP address of the receiver or target of the network traffic.
* **Source Port:** The port number used by the source IP address.
* **Destination Port:** The port number used by the destination IP address.
* **Protocol:** The communication protocol used (e.g., TCP, UDP, ICMP).
* **Packet Length:** The size of the packet in bytes.
* **Packet Type:** Type of packet (e.g., data packet, control packet).
* **Traffic Type:** The type of traffic (e.g., web traffic, email traffic).
* **Payload Data:** The actual data transmitted in the packet.
* **Malware Indicators:** Indicators of potentially malicious activity or presence of malware.
* **Anomaly Scores:** Scores indicating deviations from expected behavior, used for anomaly detection.
* **Alerts/Warnings:** Notifications or warnings generated by security systems or monitoring tools.
* **Attack Type:** Type of attack detected or suspected (e.g., DDoS, SQL injection).
* **Attack Signature:** Specific patterns or signatures associated with known attacks.
* **Action Taken:** Actions performed in response to detected threats or anomalies.
* **Severity Level:** The level of severity associated with an alert or event (e.g., low, medium, high).
* **User Information:** Information about the user involved in the network activity.
* **Device Information:** Information about the device involved in the network activity (e.g., device type, operating system).
* **Network Segment:** The segment or subnet of the network where the activity occurred.
* **Geo-location Data:** Geographical location information associated with IP addresses.
* **Proxy Information:** Information about proxy servers involved in the network communication.
* **Firewall Logs:** Logs generated by firewall devices indicating allowed or blocked traffic.
* **IDS/IPS Alerts:** Alerts generated by Intrusion Detection Systems (IDS) or Intrusion Prevention Systems (IPS) indicating suspicious or malicious activity.
* **Log Source:** The source or origin of the log entry (e.g., name of the logging system or device).
"""